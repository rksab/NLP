{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP1xccDha9J3m0XCrQAFItB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rksab/NLP/blob/main/Fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roadmap\n",
        "* Fine tune a pre-trained model\n",
        "* Download yelp review dataset\n",
        "* Train sentiment analyser on it\n",
        "* We'll use AutoTokenizer and AutoModel from hugging face.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EeoFTvtA_Agn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "EsvTLmIdlR2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Same as before\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"This course is amazing!\",\n",
        "]\n",
        "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# This is new\n",
        "batch[\"labels\"] = torch.tensor([1, 1])\n",
        "\n",
        "optimizer = AdamW(model.parameters())\n",
        "loss = model(**batch).loss\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "1GAN3I6q_YQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "b-9LxAKeK6La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "FWCxiVl_RyhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = load_dataset(\"yelp_review_full\")"
      ],
      "metadata": {
        "id": "jENOi979K7qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "sf3ViUa8SriP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].select(range(12000))\n",
        "dataset['test'] = dataset['test'].select(range(1000))"
      ],
      "metadata": {
        "id": "8kkc4h-l3NSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][:5]"
      ],
      "metadata": {
        "id": "_kp84uXcTbCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].features"
      ],
      "metadata": {
        "id": "a4faD9cXTp1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we've ratings from 1-5. Let's add a function which adds sentiment to the dataset."
      ],
      "metadata": {
        "id": "rMhI8xW8aDmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change ratings to 3 sentiments: negative: 0, positive: 1 and neutral: 2\n",
        "def transform(sentence):\n",
        "  rating = sentence['label']\n",
        "  if rating < 3:\n",
        "    return {\"sentiment\": 0}\n",
        "  else:\n",
        "    return {\"sentiment\": 1}"
      ],
      "metadata": {
        "id": "3Iecp840ZQoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(transform)"
      ],
      "metadata": {
        "id": "qQ8nfPXVZkbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'][0]"
      ],
      "metadata": {
        "id": "AcC64IapZxNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the dataset\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['text'], truncation=True)\n"
      ],
      "metadata": {
        "id": "36MXyp6yag1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "lP1plqb8d7am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['test'].features\n",
        "tokenized_datasets['test']['labels']"
      ],
      "metadata": {
        "id": "U1-1oEGPnWEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ude-fvXldwhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets[\"train\"].column_names"
      ],
      "metadata": {
        "id": "91GDcDWjvX4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(\"label\")\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"sentiment\", \"labels\")\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(\"text\")"
      ],
      "metadata": {
        "id": "uGUQND9DhgtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator\n",
        ")\n"
      ],
      "metadata": {
        "id": "yNQfVSTEs78K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "uk7JUhfKvnkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train'].features"
      ],
      "metadata": {
        "id": "nj9bz8Emmuyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")\n"
      ],
      "metadata": {
        "id": "SLekUWrdgUh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n"
      ],
      "metadata": {
        "id": "c9wrWeFNgcYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)\n"
      ],
      "metadata": {
        "id": "p0KTArO5tFnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n"
      ],
      "metadata": {
        "id": "HR2jaVy3iyYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "P2ds6W4_i2XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "dgWubK6xv2pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "Ovwiz4dVv8qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "id": "I9dDYMvdv_Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "P36tm_rTxB-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        # Get predicted class\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # Add to metric\n",
        "        accuracy.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    eval_result = accuracy.compute()\n",
        "    print(f\"Epoch {epoch+1} eval accuracy: {eval_result['accuracy']:.4f}\")\n",
        "    model.train()  # go back to training mode"
      ],
      "metadata": {
        "id": "uSS07z9XwAA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}